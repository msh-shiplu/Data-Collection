{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cerebralcortex import Kernel\n",
    "import json\n",
    "# from IPython.display import display\n",
    "# import cufflinks as cf\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, ModuleMetadata\n",
    "from cerebralcortex.core.util.spark_helper import get_or_create_sc\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "pd.set_option('display.max_rows',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='mperf')\n",
    "\n",
    "accelerometer_right_wrist_stream_name = 'accelerometer--org.md2k.motionsense--motion_sense_hrv--right_wrist'\n",
    "gyroscope_right_wrist_stream_name = 'gyroscope--org.md2k.motionsense--motion_sense_hrv--right_wrist'\n",
    "\n",
    "all_users = CC.list_users()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_accel_data(data):\n",
    "#     data = np.array([accel_x, accel_y, accel_z]).T\n",
    "    mg = np.mean([np.linalg.norm(x) for x in data])\n",
    "    if mg < 0.8:\n",
    "        return 0\n",
    "    return 1\n",
    "udf_is_correct_accel_data = F.udf(is_correct_accel_data, IntegerType())\n",
    "\n",
    "def correct_accel(data, is_correct):\n",
    "    if is_correct == 1:\n",
    "        return data\n",
    "    data = np.array(data)*2\n",
    "    return data.tolist()\n",
    "udf_correct_accel = F.udf(correct_accel, ArrayType(DoubleType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"count\", IntegerType())])\n",
    "@F.pandas_udf(schema, F.PandasUDFType.GROUPED_MAP)\n",
    "def get_data_count_udf(user_data):\n",
    "#     if len(user_data.index) < 600:\n",
    "#         return pd.DataFrame([], columns=['timestamp', 'accel', 'gyro'])\n",
    "    is_movement = []\n",
    "    correct_data = []\n",
    "    for index, row in user_data.iterrows():\n",
    "        al = len(row['accelerometer_x'])\n",
    "        gl = len(row['gyroscope_x'])\n",
    "        if al<400:  # 25 * 20 * 60% (frequency * window_size * threshold%)\n",
    "            is_movement.append(0)\n",
    "            correct_data.append(1)\n",
    "            continue\n",
    "    \n",
    "        accel_data = np.array([*row['accelerometer_x'], *row['accelerometer_y'], *row['accelerometer_z']])\n",
    "        \n",
    "        accel_data = accel_data.reshape(-1, al)\n",
    "        accel_data = accel_data.T\n",
    "        if not is_correct_accel_data(accel_data):\n",
    "            ax = 2*np.array(row['accelerometer_x']).tolist()\n",
    "            ay = 2*np.array(row['accelerometer_y']).tolist()\n",
    "            az = 2*np.array(row['accelerometer_z']).tolist()\n",
    "            accel_data = np.array([*ax, *ay, *az])\n",
    "            accel_data = accel_data.reshape(-1, al)\n",
    "            accel_data = accel_data.T\n",
    "            correct_data.append(0)\n",
    "        else:\n",
    "            correct_data.append(1)\n",
    "        mg = [np.linalg.norm(x) for x in accel_data]\n",
    "        sd= np.std(mg)\n",
    "        if sd >= 0.21:\n",
    "            is_movement.append(1)\n",
    "        else:\n",
    "            is_movement.append(0)\n",
    "    user_data['is_movement'] = is_movement\n",
    "    user_data['correct'] = correct_data\n",
    "    data_movement = user_data[user_data['is_movement']==1]\n",
    "    return pd.DataFrame(data={'count':[len(data_movement.index)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"timestamp\", TimestampType()), StructField(\"accel\", ArrayType(ArrayType(DoubleType()))), StructField(\"gyro\", ArrayType(ArrayType(DoubleType())))])\n",
    "# schema = StructType([StructField(\"count\", IntegerType())])\n",
    "@F.pandas_udf(schema, F.PandasUDFType.GROUPED_MAP)\n",
    "def get_data_udf(user_data):\n",
    "#     if len(user_data.index) < 600:\n",
    "#         return pd.DataFrame([], columns=['timestamp', 'accel', 'gyro'])\n",
    "    is_movement = []\n",
    "    correct_data = []\n",
    "    for index, row in user_data.iterrows():\n",
    "        al = len(row['accelerometer_x'])\n",
    "        gl = len(row['gyroscope_x'])\n",
    "        if al<400:  # 25 * 20 * 60% (frequency * window_size * threshold%)\n",
    "            is_movement.append(0)\n",
    "            correct_data.append(1)\n",
    "            continue\n",
    "    \n",
    "        accel_data = np.array([*row['accelerometer_x'], *row['accelerometer_y'], *row['accelerometer_z']])\n",
    "        \n",
    "        accel_data = accel_data.reshape(-1, al)\n",
    "        accel_data = accel_data.T\n",
    "        if not is_correct_accel_data(accel_data):\n",
    "            ax = 2*np.array(row['accelerometer_x']).tolist()\n",
    "            ay = 2*np.array(row['accelerometer_y']).tolist()\n",
    "            az = 2*np.array(row['accelerometer_z']).tolist()\n",
    "            accel_data = np.array([*ax, *ay, *az])\n",
    "            accel_data = accel_data.reshape(-1, al)\n",
    "            accel_data = accel_data.T\n",
    "            correct_data.append(0)\n",
    "        else:\n",
    "            correct_data.append(1)\n",
    "        mg = [np.linalg.norm(x) for x in accel_data]\n",
    "        sd= np.std(mg)\n",
    "        if sd >= 0.21:\n",
    "            is_movement.append(1)\n",
    "        else:\n",
    "            is_movement.append(0)\n",
    "    user_data['is_movement'] = is_movement\n",
    "    user_data['correct'] = correct_data\n",
    "    data_movement = user_data[user_data['is_movement']==1]\n",
    "    current = len(data_movement.index)\n",
    "    \n",
    "    if len(data_movement.index) == 0:\n",
    "        return pd.DataFrame([], columns=['timestamp', 'accel', 'gyro'])\n",
    "#     leap = 1# int(np.floor(len(data_movement.index) / 600))\n",
    "    ts = []\n",
    "    adt = []\n",
    "    gdt = []\n",
    "    tot = int(np.ceil(len(data_movement.index)*600/user_data['Available'].iloc[0]))\n",
    "    for i in range(len(data_movement.index)):\n",
    "        row = data_movement.iloc[i]\n",
    "        al = len(row['accelerometer_x'])\n",
    "        gl = len(row['gyroscope_x'])\n",
    "        ts.append(row['timestamp'])\n",
    "        if row['correct']==1:\n",
    "            accel_data = np.array([*row['accelerometer_x'], *row['accelerometer_y'], *row['accelerometer_z']])\n",
    "        else:\n",
    "            ax = 2*np.array(row['accelerometer_x']).tolist()\n",
    "            ay = 2*np.array(row['accelerometer_y']).tolist()\n",
    "            az = 2*np.array(row['accelerometer_z']).tolist()\n",
    "            accel_data = np.array([*ax, *ay, *az])\n",
    "                                   \n",
    "        gyro_data = np.array([*row['gyroscope_x'], *row['gyroscope_y'], *row['gyroscope_z']])\n",
    "        accel_data = accel_data.reshape(-1, al)\n",
    "        gyro_data = gyro_data.reshape(-1, gl)\n",
    "        accel_data = accel_data.T\n",
    "        gyro_data = gyro_data.T\n",
    "        \n",
    "        adt.append(accel_data.tolist())\n",
    "        gdt.append(gyro_data.tolist())\n",
    "        if len(ts)>=tot:\n",
    "            break\n",
    "    return pd.DataFrame(data={'timestamp': ts, 'accel': adt, 'gyro': gdt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(msg):\n",
    "    with open('calc_log.txt', 'a+') as f:\n",
    "        f.write(str(datetime.now())+\" => \"+msg+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('done_users.p', 'rb') as f:\n",
    "    done_users = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx1, mx2, mx3 = 0, 0, 0\n",
    "for user in done_users:\n",
    "    user_id = int(user[6:])\n",
    "    if user_id < 5000:\n",
    "        mx1 = max(mx1, user_id)\n",
    "    elif user_id < 9000:\n",
    "        mx2 = max(mx2, user_id)\n",
    "    else:\n",
    "        mx3 = max(mx3, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in all_users:\n",
    "    user_id = user['user_id']\n",
    "#     user_id = 'mperf_1000'\n",
    "    user_name = user['username']\n",
    "    if not os.path.exists('data_old/'+user_name+'.csv.gz'):\n",
    "        continue\n",
    "    if os.path.exists('data/'+user_name+'.csv.gz'):\n",
    "        continue\n",
    "    idd = int(user_name[6:])\n",
    "#     if idd < 5000:\n",
    "# #         continue\n",
    "#         if idd<=mx1:\n",
    "#             continue\n",
    "#     elif idd < 9000:\n",
    "# #         continue\n",
    "#         if idd<=mx2:\n",
    "#             continue\n",
    "#     else:\n",
    "# #         continue\n",
    "#         if idd <= mx3:\n",
    "#             continue\n",
    "    write_log('Starting for '+user_name)\n",
    "    try:\n",
    "        accel_ds = CC.get_stream(accelerometer_right_wrist_stream_name, user_id=user_id).filter(\"accelerometer_x >= -4 AND accelerometer_x <= 4 AND accelerometer_y >= -4 AND accelerometer_y <= 4 AND accelerometer_z >= -4 AND accelerometer_z <= 4\")\n",
    "        gyro_ds = CC.get_stream(gyroscope_right_wrist_stream_name, user_id=user_id).filter(\"gyroscope_x >= -250 AND gyroscope_x <= 250 AND gyroscope_y >= -250 AND gyroscope_y <= 250 AND gyroscope_z >= -250 AND gyroscope_z <= 250\")\n",
    "        accel_w = accel_ds.sort(F.asc('timestamp')).window(windowDuration=20)\n",
    "        gyro_w = gyro_ds.sort(F.asc('timestamp')).window(windowDuration=20)\n",
    "        gyro_w = gyro_w.drop(\"version\", \"user\")\n",
    "        common_ds = accel_w.join(gyro_w, on=\"window\")\n",
    "        common_ds = common_ds.withColumn('timestamp', F.udf(lambda w: w[0], TimestampType())('window')).drop('window')\n",
    "#         ali_df=common_ds.withColumn(\"timestamp\",  common_ds.window.start)\n",
    "#         ali_df.compute(get_data_udf, window=60*60*24)\n",
    "        windowDuration = \"1 day\"\n",
    "        groupbycols = [\"user\", \"version\"]\n",
    "\n",
    "        win = F.window(\"timestamp\", windowDuration=windowDuration)\n",
    "\n",
    "        groupbycols.append(win)\n",
    "        count_data = common_ds._data.groupBy(groupbycols).apply(get_data_count_udf)\n",
    "        total = count_data.agg(F.sum(\"count\")).collect()[0][0]\n",
    "        if total < 600:\n",
    "            write_log(\"No data for \"+user_name)\n",
    "            continue   \n",
    "        common_ds = common_ds.withColumn('Available', F.lit(total))\n",
    "        \n",
    "        data = common_ds._data.groupBy(groupbycols).apply(get_data_udf)\n",
    "#         CC.save_stream(ali_df)\n",
    "#     get_stream(version=\"latest\")\n",
    "        pdf = data.toPandas()\n",
    "        if len(pdf.index) > 0:\n",
    "#             pdf['accel'] = pdf['accel'].apply(lambda x: json.loads(x))\n",
    "#             pdf['gyro'] = pdf['gyro'].apply(lambda x: json.loads(x))\n",
    "            pdf.to_csv('data/'+user_name+\".csv.gz\", compression='gzip', index=False)\n",
    "            write_log('End for '+user_name)\n",
    "        else:\n",
    "            write_log(\"No data for \"+user_name)\n",
    "    except Exception as e:\n",
    "        write_log('Error for '+user_name)\n",
    "        write_log(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3 High Performance",
   "language": "python",
   "name": "cc3_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
